[{"categories":null,"content":" 各位看官，如果本站内容对您有帮助，欢迎赞助我一杯咖啡☕️ 毕竟，来都来了 😁 支付宝 微信支付 ","date":"2021-03-31","objectID":"/donate/:0:0","tags":null,"title":"Donate","uri":"/donate/"},{"categories":["LCTT"],"content":"开启技术翻译道路","date":"2021-03-31","objectID":"/lctt-foreword/","tags":["LCTT","开源"],"title":"LCTT项目序言","uri":"/lctt-foreword/"},{"categories":["LCTT"],"content":"什么是LCTT LCTT 是 “Linux中国” 的翻译组，负责从国外优秀媒体翻译 Linux 相关的技术、资讯、杂文等内容。 ","date":"2021-03-31","objectID":"/lctt-foreword/:1:0","tags":["LCTT","开源"],"title":"LCTT项目序言","uri":"/lctt-foreword/"},{"categories":["LCTT"],"content":"加入 LCTT 的初衷 前不久我参与了《On Java 8》的翻译工作。在这个过程中，我需要查询很多专业名词的翻译，往往纠结句子中个别单词怎么翻译比较好。虽然有痛苦，但也为我带来欢乐。我热衷于揣摩作者的表达意图，常常想他是在怎样的技术储备下写出这本书。更重要的是，在翻译过程中我对 Java 有了新的认识，而这些认识也是我之前看中文文献时疑惑的点。 不难看出，这次翻译工作为我带来了技术上的成长，也让我看到个人的能力不足。读研期间，导师让我阅读原始文献，避免受到翻译软件、译者的干扰，直接学习作者表达的内容。我想，在未来的工作中，我的阅读侧重点也应该倾向于原始文献。于是，我开始查找国内有没有优秀的国外文献阅读、学习的社区，LCTT 就是这个时候映入我的眼帘。 LCTT 社区中的文章由专业的选题人员选择，一般为技术访谈、博客等。后期由译者翻译、校对人员审核后再发布到 Linux中国社区。我作为译者参与社区工作，选择自己感兴趣的文章，翻译后提交给社区。我的工作让我见识到国外优秀的技术文章，它们介绍了实用的代码工具、翔实的技术总结、完整的调试过程，这些都可以拓宽我的技术视野，提升我的技术实力。同时，我也希望我的工作能为国内的开发者提供一些帮助，让大家在技术分享中共同进步。 ","date":"2021-03-31","objectID":"/lctt-foreword/:2:0","tags":["LCTT","开源"],"title":"LCTT项目序言","uri":"/lctt-foreword/"},{"categories":["LCTT"],"content":"我的工作展示 欢迎大家访问我的 LCTT 主页 👉 Qian.Sun 我负责的所有文章均在主页中列出 ","date":"2021-03-31","objectID":"/lctt-foreword/:3:0","tags":["LCTT","开源"],"title":"LCTT项目序言","uri":"/lctt-foreword/"},{"categories":["LCTT"],"content":"特别说明 本博客中 LCTT 专栏仅转载本人翻译的文章； 翻译工作和译文发表仅用于学习和交流目的； 翻译工作遵照 CC-BY-NC-SA 协议规定，如果我的工作有侵犯到您的权益，请及时联系我； 转载敬请在正文中标注并保留原文/译文链接和作者/译者等信息； LCTT 专栏内所有译文由 LCTT 原创翻译，Linux 中国首发。 ","date":"2021-03-31","objectID":"/lctt-foreword/:4:0","tags":["LCTT","开源"],"title":"LCTT项目序言","uri":"/lctt-foreword/"},{"categories":null,"content":"我是谁 大家好！👏 我是孙乾。自小成长在美丽的威海，如今居住在北京。 现在在中国科学院计算技术研究所，攻读计算机系统结构💻硕士学位。本科就读大连海事大学，获得了工学学士学位。目前，我主要关注5G基带算法的研究与优化。待研究结束后，我将致力于软件的开发工作。 在雁栖湖生活的日子里，我找到了美好的爱情，她是一位善良💗、可爱、大气、正直的小仙女。我们在一起经历了许多许多，品尝着平凡生活的酸甜苦辣。她帮助我改掉生活的陋习、培养品味与审美，支持我，鼓励我，是我的良师益友。我会在博客中分享我们的故事。 我爱好电影、美食、游泳，也喜欢在观众面前分享我的见解。我喜欢整理，欣赏整整齐齐的东西，包括整洁的代码与文档、干爽的桌面与客厅，有些时候达到了强迫症的程度。我喜欢做系统性的研究，研究对象是不设限制的，乐于分享最终的结果，也期待他人的见解 :) ","date":"2021-03-30","objectID":"/about/:0:1","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"博客会有哪些内容 博客中会分享我对计算机技术的整理与见解、我在职场中的成长与感悟。 还会有我对前沿论文的解读、对大型工程的源码剖析。 不定期有生活中的趣事与总结，例如上文中挖好的坑、年度总结。 ","date":"2021-03-30","objectID":"/about/:0:2","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"沟通交流最重要 我十分期待你的反馈！:) 如果你不认同我博客中的内容，一定要联系我！让我们在沟通中共同成长进步！ 可以通过首页中展示的任何渠道联系到我☎️ ","date":"2021-03-30","objectID":"/about/:0:3","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"我的分享 我会列出我最近的十次分享(可能也没有十次😅) 标题 活动 地点 时间 链接 轻松进大厂的简单方法 我把经验留下来 中科院计算所 2021.2.27 Video、Slide ","date":"2021-03-30","objectID":"/about/:0:4","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"推荐的博客 我会列出优秀的技术博客📝，这些博主都是我学习的榜样。他们的技术实力与工作履历十分精彩。 Cizixs ice1000 io-meter ","date":"2021-03-30","objectID":"/about/:0:5","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"简历 我会不定期更新我的简历，大家可以关注我的领英: Qian Sun ","date":"2021-03-30","objectID":"/about/:0:6","tags":null,"title":"About me","uri":"/about/"},{"categories":["Java"],"content":"本文介绍了 Java 线程池中所有参数配置项与要求，针对不同业务场景提供对应的配置建议","date":"2021-03-30","objectID":"/java-concurrency-3/","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"配置线程池大小 线程池的理想大小取决于被提交任务的类型以及所部署系统的特性。在实际工程中，通常不会固定线程池大小，应该通过某种配置机制来提供，或者根据 Runtime.availableProcessors 来动态计算。 在配置线程池大小时，应该避免“过大”和“过小”这两种极端情况。如果线程池过大，那么大量的线程将在相对很少的 CPU 和内存资源上发生竞争，不仅消耗更高的内存，而且还可能耗尽资源。如果线程池过小，将导致许多空闲处理器无法执行工作，从而降低吞吐率。 对于计算密集型的任务，在拥有 $N_{cpu}$ 个处理器系统上，当线程池的大小为 $N_{cpu}+1$ 时，通常能实现最优的利用率。 对于包含 I/O 操作或者其他阻塞操作的任务，由于线程并不会一直执行，因此线程池的规模应该更大。要正确设置线程池大小，你必须估算出任务的等待时间与计算时间的比值。这种估算不需要很精确，并且可以通过一些分析或监控工具来获得。 要使处理器达到期望的使用率，线程池的最优大小等于： $$N_{threads}=N_{cpu}\\times U_{cpu}\\times \\left( 1+\\frac{W}{C} \\right)$$ 式中，$N_{cpu}$ 代表 CPU 的数量，$U_{cpu}$ 代表 CPU 目标利用率，$U_{cpu}\\in [0,1]$，$\\frac{W}{C}$ 代表等待时间与计算时间的比值。 可以通过 Runtime 来获得 CPU 的数目： int N_CPUS = Runtime.getRuntime().availableProcessors(); CPU 周期并不是唯一影响线程池大小的资源，还包括内存、文件句柄、套接字句柄和数据库连接等。计算这些资源对线程池的约束条件是更容易的： 计算每个任务对该资源的需求量； 用该资源的可用总量除以每个任务的需求量，所得结果就是线程池大小上限。 ","date":"2021-03-30","objectID":"/java-concurrency-3/:1:0","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"配置 ThreadPoolExecutor public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u003cRunnable\u003e workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { ... } ","date":"2021-03-30","objectID":"/java-concurrency-3/:2:0","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"线程的创建与销毁 以下三个参数主要负责线程的创建与销毁： corePoolSize，线程池基本大小，即在没有任务执行时线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。 maximumPoolSize，线程池最大大小，表示可同时活动的线程数量的上限。 keepAliveTime，线程池存活时间。如果某个线程的空闲时间超过了存活时间，那么将被标记为可回收的。 线程池的基本大小、最大大小和存储时间等因素共同负责线程的创建与销毁。当线程池的当前大小超过了基本大小时，被标记为可回收的线程将被终止。通过调节基本大小和存活时间，可以帮助线程池回收空闲线程占有的资源，从而使得这些资源可以用于执行其他工作。 ","date":"2021-03-30","objectID":"/java-concurrency-3/:2:1","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"管理队列任务 ThreadPoolExecutor 允许提供一个 BlockingQueue 来保存等待执行的任务。基本的任务排队方法有 3 种：无界队列、有界队列和同步移交（Synchronous Handoff）。 ArrayBlockingQueue：一个基于数组结构的有界阻塞队列，按照 FIFO 原则对任务进行排序； LinkedBlockingQueue：一个基于链表结构的无界阻塞队列，按照 FIFO 原则排序任务，吞吐量通常要高于 ArrayBlockingQueue。 SynchronousQueue：一个不存储元素的线程间同步移交，要将一个元素放入 SynchronousQueue 中，必须有另一个线程正在等待接受这个元素。如果没有线程正在等待，并且线程池的当前大小小于最大值，那么 ThreadPoolExecutor 将创建一个新的线程，否则根据饱和策略，这个任务被拒绝。 PriorityBlockingQueue：一个具有优先级的有界阻塞队列，这个队列根据优先级来安排任务，任务的优先级是通过自然顺序或 Comparator 来定义的。 ","date":"2021-03-30","objectID":"/java-concurrency-3/:2:2","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"饱和策略 当有界队列被填满后，饱和策略开始发挥作用。ThreadPoolExecutor 的饱和策略可以通过调用 setRejectedExecutionHandler 来修改。JDK 提供了几种不同的实现，每种实现包含不同的饱和策略： ThreadPoolExecutor.AbortPolicy：中止策略是默认的饱和策略，该策略将在线程池数量等于最大线程数时，抛出未检查的 RejectedExecutionException。涉及到的任务将不会执行。调用者可以捕获这个异常，然后根据需求编写自己的处理代码。 ThreadPoolExecutor.CallerRunsPolicy：既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量。它不会在线程池的某个线程中执行新提交的任务，而是在一个调用了 execute 的线程中执行该任务。 ThreadPoolExecutor.DiscardPolicy：该策略在线程池中数量等于最大线程数时，会悄悄丢弃不能执行的新增任务，不报任何异常； ThreadPoolExecutor.DiscardOldestPolicy：该策略在线程池中数量等于最大线程数时，会抛弃线程池中工作队列头部的任务（即等待时间最久的任务），并执行当前任务。 ","date":"2021-03-30","objectID":"/java-concurrency-3/:2:3","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"线程工厂 每当线程池需要创建一个线程时，都是通过线程工厂方法来完成的。默认的线程工厂方法将创建一个新的、非守护的线程，并且不包含特殊的配置信息。通过指定一个线程工厂方法，可以定制线程池的配置信息。 定制线程池配置信息在某些场景下有需求，例如希望为线程池中的线程指定一个 UncaughtExecptionHandler，或者实例化一个定制的 Thread 类用于执行调试信息的记录。 下面的例子展示了自定义线程工厂为每个创建的线程池设置更有意义的名字，在 Debug 和定位问题时非常有帮助。 public class MyThreadFactory implements ThreadFactory { private final String poolName; public MyThreadFactory(String poolName) { this.poolName = poolName; } public Thread newThread(Runnable runnable) { return new MyAppThread(runnable, poolName); } } ","date":"2021-03-30","objectID":"/java-concurrency-3/:2:4","tags":["Java","并发"],"title":"配置 Java 线程池","uri":"/java-concurrency-3/"},{"categories":["Java"],"content":"Executor框架的执行策略对线程池性能造成的影响随着业务场景不同而变化，本文介绍了四类任务对执行策略、线程池性能的影响","date":"2021-03-19","objectID":"/java-concurrency-2/","tags":["Java","并发"],"title":"任务执行策略与线程池性能","uri":"/java-concurrency-2/"},{"categories":["Java"],"content":" ThreadPool Executor框架的执行策略可以将任务的提交与执行解耦开来，为任务的制定、执行提供了相当大的灵活性。但并非所有的任务都适用于Executor框架执行策略，有些任务需要明确的指定执行策略。 依赖性任务。依赖性任务注重任务之间的执行顺序。如果线程池执行依赖性任务，需要隐含为执行策略带来约束，避免产生活跃性问题。 使用线程封闭机制的任务。任务要求 Executor 是单线程的，如果将 Executor 从单线程环境改为线程池环境，将会失去线程安全性。 对响应时间敏感的任务。这类任务需要及时响应。如果将一个运行时间较长的任务提交到单线程的 Executor 中，或者将多个运行时间较长的任务提交到一个只包含少量线程的线程池中，那么将降低该 Executor 管理的服务的响应性。 使用ThreadLocal任务。ThreadLocal 使每个线程都拥有某个变量的一个私有“版本”。只要条件允许，Executor 可以自由地重用这些线程。只有当线程本地值的生命周期受限于任务生命周期时，在线程池的线程中使用 ThreadLocal 才有意义，而在线程池的线程中不应该使用 ThreadLocal 在任务之间传递值。 只有当任务都是同类型且相互独立时，线程池的性能才能达到最佳。 ","date":"2021-03-19","objectID":"/java-concurrency-2/:0:0","tags":["Java","并发"],"title":"任务执行策略与线程池性能","uri":"/java-concurrency-2/"},{"categories":["Java"],"content":"线程饥饿死锁 依赖性任务可能造成线程池死锁。线程池中如果所有正在执行任务的线程都因等待其他仍处于工作队列中的任务而阻塞，就会引发线程饥饿死锁Thread Starvation Deadlock。 ","date":"2021-03-19","objectID":"/java-concurrency-2/:1:0","tags":["Java","并发"],"title":"任务执行策略与线程池性能","uri":"/java-concurrency-2/"},{"categories":["Java"],"content":"运行时间较长的任务 如果任务阻塞的时间过长，线程池的响应性也会变得糟糕。此外，运行时间较长的任务也会增加短任务的服务时间。 有一项技术可以缓解执行时间较长任务造成的影响，即限定任务等待资源的时间。在平台类库的大多数可阻塞方法中，都同时定义了限时版本和无限时版本，例如 Thread.join、BlockingQueue.put、CountDownLatch.await 以及 Selector.select 等。如果等待超时，那么可以把任务标识为失败，然后中止任务或重新返回队列以便随后执行。 ","date":"2021-03-19","objectID":"/java-concurrency-2/:2:0","tags":["Java","并发"],"title":"任务执行策略与线程池性能","uri":"/java-concurrency-2/"},{"categories":["杂谈分享"],"content":"避免租房踩坑","date":"2021-03-15","objectID":"/house-renting/","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"毕业季总会为我们带来各种感受，既有步入新环境的兴奋，也有为生活琐事操心的烦忧。在生活琐事中，住房问题永远是大家最关注的点。大家希望在有所居的基础上，享受洁净、明亮、宽敞的居住空间。 本文是我将租房经验加以整理、抽象得出的租房注意事项，欢迎大家补充。如果您的补充被本文采纳，我会在下方列出您的名字表示您对本文的贡献👇 注意 感谢以下同学为本文的贡献： Qian Sun 张兵 Changhao Liu Rain ","date":"2021-03-15","objectID":"/house-renting/:0:0","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"房源信息 总体来说，房源信息来源分为两类：房东直租与中介介绍。 ","date":"2021-03-15","objectID":"/house-renting/:1:0","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"房东直租 房东可以将自己的出租信息挂在网上，例如高校论坛、豆瓣、闲鱼等，租客也可以直接去小区、小区物业去打听此类信息。房东直租可以省去中介费的负担，在租金上可能也有优惠。不过需要大家擦亮眼睛，明辨出租房是否为业主所有，检查房中的水电、家居情况，与房东协商一系列使用、维修注意事项。 网上的直租信息存在中介钓鱼的可能性，需自行判断对方身份。 ","date":"2021-03-15","objectID":"/house-renting/:1:1","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"中介介绍 房东直接委托中介办理房屋出租，租客可以将自己的需求明确告诉中介，中介为你推荐合适的房子。这类方式比较省事，中介可以帮你过滤不合适的信息，替你与业主协商使用、维修注意事项，如有需要也会帮你谈价格。租客承担中介费一般为一个月租金，续签时候的中介费问题需要看各个中介公司的情况。这种方式可以快速匹配租客与房源，省心省力。 上海租房可以尝试“六六直租”APP，但需要筛选房源。 ","date":"2021-03-15","objectID":"/house-renting/:1:2","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"个人建议 如果你没有租房经验，建议找一家大型中介为你找房子，中介费权当你进入租房、购房市场的学费了。原因如下： 中介手中掌握大量房源信息，可以根据你的需求帮你快速定位。毕业季租房市场火爆，快速找到适合自己的房子是关键的第一步。 中介可以为你争取到市场上绝大多数租客可以享受到的服务，例如维修责任方、必要的家具。 双方交付房子时，中介会帮助你检查房中一切情况并登记在案，退房退押金时可作为依据。 有正规的租赁合同，省去找人看合同的麻烦。 如果有租房经验，可以直接去小区或者网上寻找房东直租信息，省去中介费岂不美滋滋。 ","date":"2021-03-15","objectID":"/house-renting/:1:3","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"看房关注的点 ","date":"2021-03-15","objectID":"/house-renting/:2:0","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"风险信息 核实出租人身份，查看身份证与房产证信息页是否匹配 检查是否有权利瑕疵，例如抵押、查封、拍卖等等 检查房屋是否非法改造，主体结构是否安全，是否动了承重墙，具体方法为看房产证 检查房屋是否存在空气质量问题 约定好违约行为，一般是市场默认的违约行为 异地租房一定要现场确认房屋情况，不要轻易确定 定金最好不要交，直接签合同交租金。如果需要交定金，一定不要轻易交 ","date":"2021-03-15","objectID":"/house-renting/:2:1","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"房屋质量 房屋的布局是否合理，是否符合你的要求 房屋采光如何，能否保证你希望的足够采光时长、强度。更详细请看建筑采光设计标准 房屋是否漏水，楼上是否漏水 房屋取暖方式，优先集体供暖 房屋燃气管、燃气阀、燃表情况，是否需要更换 房屋窗户是否漏风 家具是否齐全，家具功能是否正常 房屋电路是否正常，虽然插座出问题概率小，但必要时仍需检查 长期不住人的房屋更要小心仔细检查 房屋的隔音条件，周边环境是否有噪音 ","date":"2021-03-15","objectID":"/house-renting/:2:2","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"安全问题 小区、住宅楼的安全管理情况如何 ","date":"2021-03-15","objectID":"/house-renting/:2:3","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"费用问题 付款频率，一般来说是押一付三 退房返押金的标准，需要交付时候与房东确认好房屋细节 维修费用的承担，租客原因租客承担，非租客原因需要商量好 物业费、车位费：物业费房东承担，车位费没了解过 水、电、燃气、宽带、取暖费用租客承担 约定好违约金 ","date":"2021-03-15","objectID":"/house-renting/:2:4","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"其他有用的点 把自己收拾的干净一些，让房东相信你可以照顾好他的房子 明确和房东、中介讲清自己的需求，一开始约定好比后面追加条件要容易多 房东喜欢稳定、可长租的租客，可以表现你的工作、收入稳定 情侣比朋友合租更有优势 房东希望尽快入住，避免房屋空闲，签约速度也是房东选择租客的要素之一 ","date":"2021-03-15","objectID":"/house-renting/:3:0","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["杂谈分享"],"content":"总结 要是没有经验，推荐找中介。有后续风险问题都可以找中介解决，第三信任方是交易顺利完成的保障。自己在看房子的时候需要仔细、仔细、仔细检查风险、房屋质量、安全与费用等问题。谈好的条件一定要求落实在合同中。 最后祝大家找到自己满意的房子。如果你有其他问题，可以从首页中任意联系方式找到我。 如果你有其他建议，欢迎分享给我，方式如上👆 我会添加在文中，并留下你的姓名表示感谢。 ","date":"2021-03-15","objectID":"/house-renting/:4:0","tags":["租房","注意事项"],"title":"应届生租房注意事项（持续更新）","uri":"/house-renting/"},{"categories":["Java"],"content":"本文介绍了Executor框架，框架采用了任务提交、执行的解耦方案。为了让该方案适配不同场景，需要将多种因素考虑进执行策略中。不同的执行策略也衍生出不同的线程池，我们在使用前需要分析真实环境去选择适当的线程池。线程池异步执行多个任务，导致任务可能处于不同的状态。为了管理整个线程池的生命周期，ExecutorService提供了多种方法，一般采取awaitTermination、shutdown组合使用的方式，达到同步关闭的效果。最后，本文介绍了ScheduledThreadPool在延迟任务、周期任务的优越性，如果构建调度服务，可以采用DelayQueue。","date":"2021-03-12","objectID":"/java-concurrency-1/","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"Executor框架 我们将执行的逻辑工作单元抽象为任务，那么线程就是使任务异步执行的容器。如果把所有任务放在单个线程执行，将对应用的响应性和吞吐量造成灾难性影响。 为每个任务分配一个线程似乎是不错的解决方案，不过这对资源管理有着较高的要求。线程池缓解了这一压力，它承担了管理线程工作。java.util.concurrent 提供了一种灵活的线程池作为Executor框架的一部分。 在 Java 类库中，任务执行的主要抽象不是 Thread，而是 Executor。 public interface Executor { void execute (Runnable command); } Executor 为灵活且强大的异步任务执行框架提供了基础，为任务的提交与执行提供了标准的方法，将两个过程解耦开来。此外，Executor 实现了对生命周期的支持，以及监控管理等机制。 Executor 基于生产者-消费者模式，提交任务的操作相当于生产者，执行任务的操作类似于消费者。反之，如果想实现简单的生产消费模型，可以采用 Executor 实现。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:1:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"执行策略 Executor 框架需要设计一套任务执行策略，以解决多任务执行混乱的问题。执行策略包括以下内容： 在什么线程中执行任务？ 任务按照什么顺序执行（FIFO、LIFO、优先级）？ 有多少个任务能并发执行？ 在队列中有多少个任务在等待执行？ 如果系统需要拒绝一个任务，应该选择哪个任务？如何通知应用有任务被拒绝？ 在执行一个任务前后，应该进行哪些动作？ ","date":"2021-03-12","objectID":"/java-concurrency-1/:2:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"线程池 线程池是管理诸多线程的资源池，依靠任务保持所有等待执行的任务。工作者线程Work Thread的任务很简单：从工作队列获取一个任务，执行任务，然后返回线程池并等待下一个任务。 为每个任务分配一个线程可能引入线程新建、销毁的开销，不如让多个任务在线程池中执行。通过重用现有的线程可以分摊多个线程的开销。此外，任务不会因等待线程创建而延迟执行，提升整体响应性。用户可以通过配置线程池大小，创建足够多的线程使处理器保持忙碌状态，还可防止多线程相互竞争资源而使应用程序耗尽内存或失败。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:3:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"newFixedThreadPool newFixedThreadPool 是拥有固定数量线程的线程池，每当提交一个任务就创建一个线程，直到达到最大数量。如果某个线程因异常结束，那么线程池会补充一个新线程。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:3:1","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"newCachedThreadPool newCachedThreadPool 是可缓存的线程池，如果线程池当前规模超过处理需求，将回收空闲线程，而当需求增加时，可以添加新线程。线程池规模不存在任何限制。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:3:2","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"newSingleThreadExecutor newSingleThreadExecutor 是单线程的 Executor，如果线程因异常结束，newSingleThreadExecutor 会创建另一个线程来替代。任务按照队列顺序而执行。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:3:3","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"newScheduledThreadPool newScheduledThreadPool 的线程数量也是固定的，但可以以延迟或定时方式执行任务。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:3:4","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"Executor 的生命周期 Executor 通常会创建线程来执行任务，只有当所有线程全部终止后才会退出，如果无法正确关闭 Executor，JVM 将无法结束。 因为 Executor 以异步方式执行任务，可能引发任务状态不同步的问题。同一时刻，不同任务可能处于执行、完成、等待执行三个状态。为了解决执行任务的生命周期问题，Executor 扩展了 ExecutorService 接口，添加了一些用于生命周期管理的方法。 public interface ExecutorService extends Executor { void shutdown(); List\u003cRunnable\u003e shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // ... } ExecutorService 的生命周期有三种状态：运行、关闭和已终止。shutdown 方法将平缓地关闭 ExecutorService：不再接受新任务，同时等待已经提交的任务执行完成——包括还未开始执行的任务。shutdownNow 方法将粗暴地关闭 ExecutorService：直接取消所有执行中的任务，并且不再启动队列中尚未开始执行的任务。 awaitTermination 方式可以等待 ExecutorService 到达终止状态，或者调用 isTerminated 来轮询 ExecutorService 是否已经终止。通常在调用 awaitTermination 方法后立即调用 shutdown，从而产生同步关闭的效果。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:4:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"延迟任务与周期任务 Timer 类负责管理延迟任务以及周期任务。但 Timer 类支持的是基于绝对时间的调度机制，对系统时钟变化的容忍度很低，存在天然缺陷。ScheduledThreadPool 只支持基于相对时间的调度，可以通过 ScheduledThreadPool 的构造函数或 newScheduledThreadPool 工厂方法来创建该类的对象。 如果构建调度服务，可以使用 DelayQueue，它实现了 BlockingQueue，并为 ScheduledThreadPoolExecutor 提供调度功能。DelayQueue 管理着一组 Delayed 对象。每个 Delayed 对象都有一个相应的延迟时间。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:5:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["Java"],"content":"总结 本文一开始介绍了 Executor 框架，框架采用了任务提交、执行的解耦方案。为了让该方案适配不同场景，需要将多种因素考虑进执行策略中。不同的执行策略也衍生出不同的线程池，我们在使用前需要分析真实环境去选择适当的线程池。线程池异步执行多个任务，导致任务可能处于不同的状态。为了管理整个线程池的生命周期，ExecutorService 提供了多种方法，一般采取 awaitTermination、shutdown 组合使用的方式，达到同步关闭的效果。最后，本文介绍了 ScheduledThreadPool 在延迟任务、周期任务的优越性，如果构建调度服务，可以采用 DelayQueue。 ","date":"2021-03-12","objectID":"/java-concurrency-1/:6:0","tags":["Java","并发"],"title":"Executor与线程池","uri":"/java-concurrency-1/"},{"categories":["读书笔记"],"content":"思维混乱常常导致我们决策失误，戴上六顶思考帽，专注思考方向，全面、快速、清晰地思考","date":"2021-02-14","objectID":"/six-thinking-hats/","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["读书笔记"],"content":" 封面 ","date":"2021-02-14","objectID":"/six-thinking-hats/:0:0","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["读书笔记"],"content":"关于本书 关于本书 ","date":"2021-02-14","objectID":"/six-thinking-hats/:1:0","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["读书笔记"],"content":"内容简介 本书介绍了一种思考模式，可以应对探索性问题或者单类型问题。 六顶思考帽代表一种思维方式。每次思考时专注于一顶帽子，避免出现思维混乱的情况。 通过训练、使用，可以全面、客观、快速认清问题，并提出解决方案。 ","date":"2021-02-14","objectID":"/six-thinking-hats/:2:0","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["读书笔记"],"content":"书摘 思维导图总结 ","date":"2021-02-14","objectID":"/six-thinking-hats/:3:0","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["读书笔记"],"content":"读后感 思考是人类最大的宝藏，但非常容易出现思考混乱，情感、信息、逻辑、希望和创意搅在一起。 可以不必关注“是什么”，关注“能够怎样”，辩证法告诉我们角度不同、结论不同。 现代新事物涌现太快，需要更快速、全面地认清新事务，这套方法比较适用。 经验告诉我，使用这套方法应该是润物细无声的方式，生拉硬拽会适得其反。 ","date":"2021-02-14","objectID":"/six-thinking-hats/:4:0","tags":["读书笔记","思考方式","水平思考"],"title":"《六顶思考帽》读书笔记","uri":"/six-thinking-hats/"},{"categories":["论文学习"],"content":"自治DBMS可以降低DBA工作负担，为企业带来数据驱动决策的便利。该文提出Peloton DBMS自治架构，并认为在深度神经网络、新硬件和高性能数据库架构下，自治DBMS是可以实现的","date":"2021-01-22","objectID":"/self-driving-dbms/","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"注意 自治 DBMS 可以降低 DBA 工作负担，为企业带来数据驱动决策的便利。该文提出 Peloton DBMS 自治架构，并认为在深度神经网络、新硬件和高性能数据库架构下，自治 DBMS 是可以实现的。 原文在这里 👉 Self-Driving DBMS ","date":"2021-01-22","objectID":"/self-driving-dbms/:0:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"摘要 过去，研究员和供应商都搭建了查询工具去帮助 DBA 实现系统调优、物理设计。然而，之前大部分工作是不完整的，因为 DBA 仍无法摆脱数据库更改的裁定工作，并且在问题发生后仍需要采取应对措施。 真正的“自治”数据库管理系统Database Manage System所需要的是一种为自治而设计的新架构。这与以前的工作不同，因为系统所有方面都受集成规划组件控制，该组件不仅优化系统以适应当前负载，也预测未来的负载趋势，以便系统能够相应地进行准备。这样，DBMS 就可以支持所有以前的调优技术，而不需要人力确定正确的方式和适当的时间去部署它们。它还支持一些对现代高性能 DBMS 很重要的优化，这点在今天是很难的，因为管理这些系统的复杂性已经突破专家的能力上限。 本文介绍了第一代 Self-Driving DBMS——Peloton 的架构。由于深度学习算法的进步以及硬件、自适应数据库架构的改进，Peloton 的自主能力现在有了可能性。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:1:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"介绍 从 1970 年以来，关系模型和声明式查询语言就以消除数据管理负担为卖点。40年后，DBMS 变得更加复杂，功能越来越多。使用现有的自动调优工具是一项繁重的任务，因为它们需要费力准备工作负载样本、空闲的硬件来测试更新，最重要的原因是需要直观了解 DBMS 内部结构。如果 DBMS 可以自动完成这些事，那么它将消除部署数据库所涉及的许多复杂性和成本。 以前关于调优系统的工作关注点在针对数据库单个方面的独立工具上。例如，一些工具能够选择数据库的最佳逻辑或物理设计，如索引、分区方案、数据组织或物化视图。其他工具可以为应用选择调优参数。这些工具中的大多数都以相同的方式操作：DBA 为其提供样本数据库和工作负载跟踪，以指导搜索过程去找到最佳或接近最佳的配置。主要的 DBMS 供应商（包括 Oracle、Microsoft 和 IBM）都以这种方式操作。最近有一种推动集成组件支持自适应架构的趋势，但这同样只专注于解决一个问题。同样，云厂商使用动态资源分配服务，不会对单个数据库进行调优。 所有这些对一个完全自治的系统来说都是不够的，因为它们在 DBMS 之外，不能同时解决多个问题。也就是说，它们从系统外部观察 DBMS 的行为，并在问题发生后建议 DBA 如何修正问题。调优工具假定操作它们的人有足够的知识，可以在特定时间内更新 DBMS，不对应用产生大影响。然而，数据库领域在过去十年中发生了巨大的变化，我们不能假定 DBMS 是由一个了解数据库优化的专家部署而成。再说，即使这些这些工具可以实现自治， DBMS 架构也会在重大更新时给 DBMS 施加很大压力，也无法突破未来的瓶颈。 本文中，作者证明了自治数据库系统是可以实现的。下文首先会讨论该系统所面临的主要挑战。然后，作者提出了 Peloton 的架构，以及使用 Peloton 中集成深度学习框架的测量结果。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:2:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"问题概述 自治 DBMS 面临的第一个挑战是理解应用的负载。最基本的级别是将查询定义为 OLTP 或 OLAP 应用。如果 DBMS 确定了应用属于二者中的哪一类，那么它就可以决定如何优化数据库。例如，如果是 OLTP，DBMS 应该将元组存储在面向行的布局中，并为写进行优化。如果是 OLAP，那么 DBMS 使用面向列的布局，这样更适应访问表列子集的只读查询 。处理这个问题的一种方法是部署专门用于 OLTP 和 OLAP 负载的独立 DBMS，然后在它们之间定期流更新。但是这不适合 HTAP，因为它在数据由 OLTP 写入时就执行 OLAP 查询，所以无法将 DBMS 独立部署开。更好的方法是部署一个支持混合 HTAP 负载的 DBMS 。这种系统会自动为不同数据库段选择适当的 OLTP 或 OLAP 优化。 除了要理解应用的负载，DMS 也需要预测资源利用趋势。这帮助它能够预测未来需求和部署优化，同时对性能影响最小。许多程序的使用模式密切契合人类的日常生活。这也是为什么 DBA 会在非高峰时间安排更新，以避免正常业务时间的服务中断。不可否认，有些工作负载异常是 DBMS 无法预料的。但这些模型可以预先警告，使得 DBMS 能够比外部监控系统更快地实施缓解措施。 现在， DBMS 可以依靠这些模型去确定数据库调优与优化操作，以更好应对预期的工作负载。自治 DBMS 不支持 DBA 的任务，这些任务需要系统外部信息，比如权限、数据清洗和版本控制。如下表所示，自治 DBMS 可以支持三种优化类型。第一个是数据库物理设计，第二个是数据组织的修改，最后是影响 DBMS 的运行时行为。对于每一个优化操作，DBMS 将需要评估它们对数据库的潜在影响。这些评估不仅包括行动部署后消耗的资源，还包括 DBMS 部署行动时消耗的资源。 Types Actions PHYSICAL Indexes AddIndex, DropIndex, Rebuild, Convert PHYSICAL Materialized Views AddMatView, DropMatView PHYSICAL Storage Layout Row👉Columnar, Columnar👉Row, Compress DATA Location MoveUpTier, MoveDownTier, Migrate DATA Partitioning RepartitionTable, ReplicateTable RUNTIME Resources AddNode, RemoveNode RUNTIME Configuration Tuning IncrementKnob, DecrementKnob, SetKnob RUNTIME Query Optimizations CostModelTune, Compilation, Prefetch 即使系统能够预测程序的工作负载，选择要使用的操作 ，并确定实施操作的最佳时间，仍然存在额外的挑战。如果 DBMS 不能有效地应用这些优化，没有带来较大的性能下降，那么系统将无法快速适应变化。这也是目前自治 DBMS 不可能实现的另一个原因。如果系统只能每周更新一次，那么它很难规划如何纠正系统。因此，论文认为需要一个灵活的基于内存的 DBMS 体系结构，可以在部署过程中逐步优化，而不会对应用程序产生可察觉的影响。 最后，一个自治 DBMS 有两个额外的约束，它必须关联如今的应用程序。首先，DBMS 不能要求开发人员重写应用代码以适应自治 DBMS。第二，不能依赖只支持某些编程环境的程序分析工具。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:3:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"自治架构 研发发现现有 DBMS 对于自治操作过于笨重 ，因为它们需要在更改时重新启动，而且上表中的许多操作太慢了。因此，DBMS 需要一个崭新的架构，对集成的自治组件有更全面、更细致的控制 。 接下来描述 Peloton 架构中的组件。Peloton 架构是一种全新的架构，而不是改造现有的 DBMS（例如，Postgres/MySQL）。最重要的是，它使用了多版本并发控制，在不阻塞 OLAP 查询的前提下交叉 OLTP 事务和操作。另一个特点是，它使用了一个内存存储管理器，具有无锁的数据结构和灵活的布局，可以快速执行 HTAP 工作负载。这些设计已经使我们能够支持 Peloton 的优化操作。 Peloton架构 Peloton 的自治流程如上图所示。除了环境设置（比如内存阈值与目录路径），论文的目标是让Peloton 在没有任何人为提供的指导信息的情况下高效运行。系统自动学习如何提高应用程序查询和事物的延迟。延迟是 DBMS 中最重要的度量标准，因为它全面代表性能情况。本文的其余部分假设延迟是主要优化目标。可以为分布式环境中的其他重要指标添加额外的约束，例如服务成本和资源。 Peloton 包含一个嵌入式监视器，跟踪系统的内部事件流的执行查询。每个查询条目都标注了其资源利用率。流还定期被 DBMS/OS 遥测数据和优化操作的开始/结束事件打断。然后，DBMS 根据这些监控数据为应用程序的预期工作负载构建预测模型。它使用这些模型来识别瓶颈和其他问题（例如，缺少索引、超载节点），然后选择最佳操作。系统执行此操作的同时仍然处理应用程序的常规工作负载，并收集新的监控数据，以了解这些操作如何影响其性能。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:4:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"工作负载分类 第一个组件是 DBMS 的集群器，它使用无监督学习方法对具有类似特征的应用程序查询进行分类。集群工作负载减少了 DBMS 维护的预测模型数量，从而使预测应用程序的行为更容易（也更准确）。Peloton 的初始实现使用 DBSCAN 算法。这种方法已被用于对静态 OLTP 工作负载进行聚集操作。 这种集群的一大问题是使用什么查询特征。这两种类型的特性是查询的时间度量和查询的逻辑语义。虽然前者使 DBMS 能够更好地聚集类似的查询，且不需要理解它们的含义，但它们对数据库内容或其物理设计设计的变化更敏感。即使数据库没有更改，在高并发工作负载中也可能发生类似的问题。另一个方法是根据逻辑执行计划的结构（例如表、谓词）对查询进行分类，这些特征独立于数据库的内容及其物理设计。这些特征是否会产生集群以生成良好的预测模型还有待观察，或者运行时指标的准确性是否超过了再训练的成本。运行时度量可能会使系统在更短的时间内收敛到稳定的状态，因此系统不必经常重新训练它的预测模型。或者，即使集群经常变化，硬件加速训练也能使系统以最小 的开销加速重建模型。 下一个问题是如何确定集群何时失效。当这种情况发生时，DBMS 必须重新构建集群，这可能打乱已有的分类，并要求它重新训练所有的预测模型。Peloton 使用标准交叉验证技术来确定集群的错误率何时超过阈值。DBMS 还可以利用操作对查询的影响来决定何时重建集群。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:4:1","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"负载预测 下一步是训练预测模型，预测每个工作负载集群的查询抵达率。除了异常热点外，这种预测使系统能够识别工作负载周期性和数据增长趋势，为负载波动做好准备。在 DBMS 执行一个查询后，它用它的集群标识符标记每个查询，然后填充一个直方图📊，该直方图跟踪在一段时间内每个集群收到的查询数量。Peloton 使用这些数据来训练预测模型，预测应用程序未来将执行的每个集群的查询数。DBMS 还为事件流中的其他 DBMS/OS 指标构建了类似的模型。 以前在自治系统方面的尝试使用了 auto-regressive-moving average 模型（ARMA）来预测在云中自动伸缩的 web 服务工作负载。ARMA 可以捕获时间序列数据中的线性关系，但它们通常需要一个人来识别模型中的差分顺序和 term 的数量。此外，线性假设对于许多数据库工作负载可能并不有效，因为它们受到外部因素的影响。 RNN 是预测非线形系统时间序列模式的一种有效方法。LSTM 是 RNN 的一种变体，允许网络学习时间序列数据中的周期性和重复趋势，而常规的 RNN 无法做到这一点。LSTM 包含一些特殊的 block，用于决定是否保留旧的信息以及何时将其输出到网络中。尽管 RNN 被吹捧为能够解决许多以前难以解决的问题，但仍需要研究如何使其适用于自治 DBMS。 RNN 的准确性也依赖于它的训练集数据的大小。但是跟踪在 DBMS 中执行的每个查询都会增加模型构建的计算成本。幸运的是，我们没有必要知道将来查询的确切数量。相反，Peloton 为每个组维护多个 RNN，它们在不同的时间范围和间隔粒度上预测工作负载。尽管这些粗粒度的 RNN 不准确，但它们减少了 DBMS 必须维护的训练数据和运行时的预测成本。组合多个 RNN 使 DBMS 能够处理对精确度要求更高的即时问题，也能够适应评估范围更广的长期计划。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:4:2","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"行动计划与执行 最后一个组件是 Peloton 的控制框架，能够持续监控系统和选择优化行动，以提高应用程序的性能。这就是自治组件和 DBMS 架构紧密耦合的最明显好处，因为它使不同的部分能够相互提供反馈。作者也相信有机会在系统更多部分中使用强化学习，包括并发控制和查询优化。 行动生成：系统搜索可能提高性能的操作。Peloton 将这些操作存储在一个目录中，并记录在操作调用的历史。这种搜索是由预测模型指导的。它还可以删除冗余操作，降低搜索复杂度。 在需求竞争低时，Peloton 可以用更多的核去完成动作部署，在竞争高时，只能用更少的核。 行动计划：现在有了行动目录，DBMS 根据预测、当前数据库配置和目标函数去选择部署哪个行动。滚动时域控制模型receding-horizon control model，RHCM的基本思想：在每个时间单元，系统使用预测来估计某个有限时域的工作负载。然后，它会搜索动作，以最小化目标函数。但它只能应用于第一个动作，在下个时间单元重复流程前只好等待部署完成。这就是高性能 DBMS 至关重要的原因。如果动作在几分钟内完成，则系统不必监视工作负载是否已经转移，并决定中止正在执行的动作。 在 RHCM 下，计算过程被建模为一棵树，其中每一层包含 DBMS 可以调用每个操作的时间。该系统通过估算行动的成本效益来搜索树，并选择最低成本的行动序列。也可以选择在一个时间单元内不执行任何操作。一种降低这个过程复杂性的方法是，在搜索树的更深层次随机选择要考虑的行动，而不是评估所有可能的行动。这种抽样会加上权重，以便更有可能考虑为数据库当前状态及其预期工作负载提供最优行动。它还避免了最近调用的行动，但后来系统取消这条规则。 一个行动的成本是对部署它所需的时间估计，以及在这段时间内 DBMS 性能会下降多少。由于以前没有部署过很多行动，因此不可能总是从以前的历史记录生成这些信息。系统使用分析模型来评估每个操作类型的成本，然后通过反馈机制自动改进它们。这样的好处是在部署行动后查询的延迟时间发生了变化。这个好处来自 DBMS 的内部查询计划器成本模型。它是加权计算的行动部署后查询样本延迟改进的总和，权重是预测模型预测的期望查询完成率。 除了上述的成本-收益分析之外，系统还必须评估一个行动如何随时间推移影响 Peloton 的内存使用。任何导致 DBMS 超过内存阈值的行动都需要舍弃。 重要的是，系统在考虑行动时应该考虑多长时间跨度。太短会阻止 DBMS 及时为即将到来的负载峰值做好准备，但太长会使 DBMS 无法缓解突然出现的问题，因为模型太慢。此外，由于计算每个时间纪元的成本-收益是昂贵的，它可能创建另一个深度学习网络来近似它们值函数。 部署：Peloton 支持非阻塞方法部署行动。例如，重新组织表的布局或将其移动到不同的位置并不会阻止查询该表。有些操作，如添加索引，需要特别考虑。这样 DBMS 就不会因为在操作进行时数据被修改，导致任何错误发生。 DBMS 还从其集成的机器学习组件处理资源调度和竞争问题。使用单独的协处理器或 GPU 来处理繁重的计算任务，可以避免降低 DBMS 的速度。否则，DBMS 将不得不使用一台单独的机器，专门用于所有的预测和计算组件。这将使系统的设计复杂化，并由于协调而增加额外的开销。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:4:3","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"其他注意事项 要让自治 DBMS 得到广泛应用，还需要克服一些非技术挑战。最重要的是 DBA 不愿意将数据库控制权交给自动化系统。为了简化过渡，自治 DBMS 可以以可视化方式公开其决策过程。例如，如果它选择添加一个索引，可以向 DBA 解释，它的模型表明当前的工作负载与过去某个时间点相似，这个时间点使用这样的索引是有好处的。 还必须支持来自 DBA 的提示，说明系统是否应该更多地关注工作负载的 OLTP 或 OLAP 部分。类似的，对于多租户部署，系统需要知道是否应该对每个数据库进行相同的调优，或者一个数据库是否比其他数据库更重要。 最后，可能需要为 DBA 提供一个覆盖机制。人类发起的改变被当作其他一样的行动，Peloton 记录操作历史来决定该行动是否有益。唯一的区别是系统不允许逆转。为了防止 DBA 做出的错误决策被永久保留，DBMS 可以要求 DBA 手动设置生命周期。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:4:4","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"初步结果 作者在 Peloton 中集成了 Tensorflow，使用从一个在线讨论网站一个月的流量数据中提取 5200 万个查询来训练两个 RNN。使用 75% 的数据去训练模型，25% 数据去验证模型。在输入上应用了两个堆叠的 LSTM 层，然后连接到一个线形回归层，对这些层使用 10% 的 Drop 以避免过拟合。 第一个模型以分钟为粒度去预测下一小时将到达的查询数量。该模型收入是一个向量，表示过去两小时内每分钟的工作负载，而输出是一个标量，表示一小时后预测的工作负载。第二个模型使用 24 小时时域，粒度为 1 小时。 RNN与真实负载数据的比较结果 两个RNN的训练时间分别为 11 和 18 分钟，从下图可看出，模型能够以 11.3% 的错误率预测 1 小时后的工作负载，以 13.2% 的错误率预测一天后的。对于计算开销，前者大约是 2MB，DBMS 探测每个模型以获得新预测需要 2ms，向其添加一个新的数据点需要 5ms。 使用这些模型，可以在 Peloton 中实现数据优化操作。根据访问这些表的查询类型，将表迁移到不同布局中。每个表的“热”元组存储在行布局中，已经针对 OLTP 优化，而同一张表中“冷”元组存储在列布局中，已经针对 OLAP 优化。使用 HTAP 工作负载，白天执行 OLTP 操作，晚上执行 OLAP 查询。当启动自动布局时，在 Peloton 中执行查询序列，并将其与静态的行和列布局进行比较。 自动交叉布局与静态布局在HTAP应用中的性能比较 从上图可看出，Peloton 随着时间推移收敛到一种适合工作负载的布局。在第一段后，DBMS 将行元组迁移到列布局，适应 OLAP。接下来，当工作负载转移到 OLTP 查询时，自治 DBMS 比静态系统更好，因为它执行的内存写操作更少。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:5:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"总结 随着大数据运动兴起，对自治 DBMS 的需求越来越大。这类系统将降低人力成本在部署任何规模数据库上的浪费，并使各组织更容易享受数据驱动决策带来的便利。论文概述了 Peloton DBMS 的自治架构。作者认为，由于深度神经网络、新硬件和高性能数据库架构，自治 DBMS 系统是可以实现的。 ","date":"2021-01-22","objectID":"/self-driving-dbms/:6:0","tags":["论文","DBMS","数据库管理"],"title":"自治数据库管理系统","uri":"/self-driving-dbms/"},{"categories":["论文学习"],"content":"Lakehouse架构支持开放的数据格式、机器学习，提供卓越的性能，是第三代数据分析平台的代表","date":"2021-01-06","objectID":"/lakehouse/","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"注意 Lakehouse架构逐渐在工业界铺开，第三代数据分析平台进入大众视野！ 原文在这里 👉 Lakehouse ","date":"2021-01-06","objectID":"/lakehouse/:0:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"摘要 论文认为数据仓库架构在未来一段时间内会逐渐消亡，取而代之的是一种新型 Lakehouse架构，该架构具有如下特特性： 基于开放的数据格式，例如 Apache Parquet 完全支持机器学习和数据科学 提供卓越的性能 Lakehouse 解决数据仓库面临的主要挑战——数据陈旧、可靠性不高、总成本大、数据格式受限、场景支持受限。论文下面会讨论 Lakehouse 架构为何取得工业界青睐以及如何影响数据管理。 ","date":"2021-01-06","objectID":"/lakehouse/:1:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"数据分析平台发展 数据仓库将业务数据库的数据收集到集中式仓库，帮助企业领导分析数据，之后被用于决策支持和商业智能Business Intelligence。数据仓库使用写模式schema-on-write写入数据，优化下游BI消费的数据模型。这就是第一代数据分析平台。 第一代数据分析平台 后来第一代平台开始面临诸多挑战。首先是计算与存储耦合使得扩容成本增加，这迫使企业支付用户负载和数据管理峰值的成本，这个成本随着数据规模增加而迅速增加。其次，越来越多的数据集是非结构化的，例如视频、音频和文本文档，而数据仓库无法存储、查询这类数据。 为了解决这些问题，第二代数据分析平台将所有原始数据导入数据湖：具有文件 API 的低成本存储系统，该系统可存储开放数据格式，例如 Apache Parquet 和 ORC。这个方法源起于 Apache Hadoop，基于 HDFS 实现低成本存储。数据湖是一种读模式schema-on-read架构，可以灵活、低成本地存储数据，也解决了数据质量和下游管理的问题。该架构中的一小部分数据在进行 ETL 后注入下游数据仓库，再进行决策支持和 BI 分析。开放数据格式使得绝大多数分析引擎可以直接访问数据湖数据。 第二代数据分析平台（数据湖+数据仓库） 2015年起，云数据湖（S3、ADLS、GCS、OSS等）开始取代HDFS，它们具有超强的持久性、冗余可靠、超低存储成本。云上架构与第二代平台架构相同，例如Redshift、Snowflake。数据湖 + 数据仓库 两层架构当今在工业界中占主导地位。 如今，这种架构面临新的挑战。尽管存储和计算的分离使得云数据湖 + 数据仓库架构的成本降低，可增加了用户的使用成本。在第一代平台中，所有业务数据库中的数据经过ETL后直接注入数据仓库。第二代平台却在中间引进了数据湖，增加了额外的复杂性、延迟与故障率。同时，数据湖 + 数据仓库二层架构不能很好支持机器学习之类的高级分析。具体来看，可以归纳为四个问题： 可靠性。保持数据湖与数据仓库的一致性是成本高昂且困难的事情。需要对两个系统之间的 ETL 作业进行仔细设计，如此方可进行高性能决策支持与 BI 分析。每个ETL步骤还有发生故障或引入错误的风险，例如由于数据湖和数据仓库引擎之间的细微差别而导致数据质量降低的风险。 数据陈旧。数据仓库数据的时效性低于数据湖数据，新数据的加载通常要花费几天。与第一代分析系统相比，这是个倒退，第一代分析系统可以直接查询新的业务数据。根据 Dimensional Research 与 Fivetran 调查，86% 的分析使用过时数据，62% 的报告每月需要等待几次引擎资源。 对高级分析支持有限。企业希望使用数据进行预测，例如“我应该为哪些顾客提供折扣？”。 尽管许多研究关注机器学习与数据管理结合，但主流机器学习系统没有一个可以工作在数据仓库上，包括 TensorFlow、PyTorch 和 XGBoost。与 BI 查询少量数据不同，这些机器学习系统需要使用复杂的 No-SQL 代码处理大型数据集，但通过 ODBC/JDBC 读取数据效率很低，并且无法直接访问数据仓库内部专有格式的数据。对于这类场景，数据仓库供应商建议导出数据为文件，但这增加了复杂性和滞后性，因为添加了第三个 ETL。或者，用户可以在支持开发格式的数据湖上运行这些系统，这会抛弃数据仓库丰富的数据管理功能，例如 ACID 事务、数据版本控制与索引。 总成本。除了支付 ETL 作业费用外，用户还得为复制到数据仓库的数据支付两倍的存储成本，而数据仓库使用的内部格式额外引入数据或工作负载迁移到其他系统的成本。 一种被广泛采用的解决方案是不使用数据湖 ，将所有数据存储在计算、存储分离的数据仓库中。论文认为这种方案可行性有限，因为不支持视频、音频和文本数据或从机器学习和数据科学工作负载中直接访问。 论文作者提出了一个问题：是否可以将基于开放数据格式（Parquet 与 ORC）的数据湖转为一个高性能系统，该系统既拥有数据仓库强大的性能、管理功能，又可直接、快速访问高级分析工作负载？随着越来越多的业务应用开始依赖运营数据和高级分析，Lakehouse 架构可以消除数据仓库的上述挑战。 作者相信 Lakehouse 的时机已经到来！ Lakehouse架构 Lakehouse可解决以下问题： 数据湖上可靠的数据管理：Lakehouse 需要存储原始数据，同时支持 ETL/ELT 流程来提高数据分析质量。传统数据湖将半结构化数据以“一堆文件”形式进行管理，很难提供一些简化ETL/ELT的关键管理功能，例如事务、回滚、零拷贝。然而，以 Delta Lake 和 Apache Iceberg 为代表的新型数据湖框架提供了数据湖的事物视图，并提供了管理功能，减少 ETL 步骤，并且分析人员可以高效查询原始数据表，这与第一代分析平台很像。 支持机器学习和数据科学：机器学习系统支持直接读取数据湖数据格式，很多系统采用 DataFrames 作为操作数据的抽象，而声明式 DataFrame APIs 可以为机器学习工作负载中的数据访问进行查询优化，可以让机器学习工作负载直接享受 Lakehouse 的优化点。 SQL性能：Lakehouse 需要在海量 Parquet/ORC 数据集上提供很好的 SQL 性能，相比之下经典数据仓库对 SQL 优化更彻底。尽管如此，论文提出需要维护 Parquet/ORC 数据集的辅助数据，在现有格式内优化数据布局以实现更好的性能。 ","date":"2021-01-06","objectID":"/lakehouse/:2:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"出发点：数据仓库的挑战 当前工业界对数据仓库不是很满意。首先是数据质量和可靠性不高，维护数据流分析的准确性是一件很困难的工作。其次，越来越多的商业分析需要最新的数据，但数据仓库不可避免地引入数据滞后性。第三，如今的非结构化数据比重大幅增加，但数据仓库并不能提供很好的非结构化数据分析。最后，现在工业界部署的机器学习与数据科学应用无法从数据仓库和数据湖中得到很好的支持。 当前工业界对数据湖 + 数据仓库的两层架构并不满意。首先是几乎所有的数据仓库近期都增加了对 Parquet 和 ORC 格式的外部表支持，允许数据仓库用户可以从相同的 SQL 引擎查询数据湖表，但这没有降低数据湖管理难度，也没有消除数据仓库 ETL 复杂度、滞后性和高级分析挑战。实际上，这些支持的性能通常较差，因为 SQL 引擎主要针对其内部数据格式进行了优化。其次，直接针对数据湖存储的 SQL 引擎也有广泛产品，例如 Spark SQL、Presto、Hive 和 AWS Athena。然而，这些引擎不能解决数据湖所有问题，也不能取代数据仓库，数据湖仍然缺少包括 ACID 事务的基础管理功能和有效访问方法，例如与数据仓库性能匹配的索引。 ","date":"2021-01-06","objectID":"/lakehouse/:3:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"Lakehouse 架构 论文为 Lakehouse 提出一个定义：基于低成本、直接访问存储的数据管理系统，该系统具有传统分析型 DBMS 管理和性能，例如 ACID 事务、数据版本管理、数据审计、索引、缓存和查询优化。可以看出，Lakehouse 结合了数据湖和数据仓库的核心优势。问题的关键在于是否可以有效结合这些优势，特别是 Lakehouse 对直接访问的支持意味着其放弃了部分数据独立性。 Lakehouse 天然适合计算、存储分离的云环境：不同的计算应用程序按需分配在完全独立的计算节点（例如 ML 的 GPU 集群），同时直接访问相同的存储数据，但也可以在本地存储系统（如 HDFS）上实现 Lakehouse。 ","date":"2021-01-06","objectID":"/lakehouse/:4:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"实现 Lakehouse 系统 实现 Lakehouse 的第一个关键思想是使用标准文件格式（如 Parquet）将数据存储在低成本的对象存储（如 Amazon S3、OSS）中，并在对象存储上实现元数据层，其定义了哪些对象是表版本一部分。这使系统可以在元数据层实现如 ACID 事务处理或版本控制之类的管理功能，同时将大量数据保存在低成本对象存储中，并允许客户端使用使用标准文件格式直接从该存储中读取对象。 尽管元数据层增加了管理功能，但不足以实现良好的 SQL 性能。数据仓库使用多种技术获得性能提升，比如将热数据存储在 SSD 等高速设备、维护统计信息、构建有效的访问方法（如索引）以及优化数据格式和计算引擎。基于现有存储格式的 Lakehouse 无法变更格式，但是也可以实现保持数据文件不变情况下的其他优化，包括缓存、辅助数据结构（例如索引和统计信息）和数据布局优化。 最终，Lakehouse 既可以加快高级分析负载，又可以为其提供更好的数据管理功能。许多机器学习库（如 Tensorflow 和 Spark MLlib）已经可以读取数据湖文件格式（如 Parquet）。因此将它们与 Lakeehouse 集成最简单方法是查询元数据层，查询哪些 Parquet 文件属于表，然后将它们传递给机器学习库。这些系统支持 DataFrame API，以便进行更好的优化。R 与 Pandas 推广了 DataFrames，为用户提供包含多种操作符的表抽象，其中大多数映射到关系代数。Spark SQL 等系统通过惰性计算转换与传递结果操作步骤到优化器实现该 API 声明式。因此，这些 API 可利用 Lakehouse 新优化特性实现机器学习加速，例如缓存和辅助数据。 APIs and Lakehouse ","date":"2021-01-06","objectID":"/lakehouse/:4:1","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"用于数据管理的元数据层 Lakehouses 的第一个组件是元数据层，其可以实现 ACID 事务和其他管理功能。诸如 S3 或 HDFS 之类的数据湖存储系统仅提供了低级的对象存储或文件系统接口，在这些接口中，即使是简单的操作（如更新跨多个文件的表）也不是原子的，这个问题使得一些组织开始设计更丰富的数据管理层，从 Apache Hive ACID 开始，其使用 OLTP DBMS 跟踪给定表版本中哪些数据文件是 Hive 表的一部分，并允许操作以事务方式更新此集合。近年来一些新系统提供了更多功能和改进的可伸缩性，如 2016 年 Databricks 开发的 Delta Lake，其将有关哪些对象是表中一部分的信息存储在数据湖中，作为 Parquet 格式的事务日志，使其能够扩展到每张表数十亿个对象；Netflix 的 Apache Iceberg 也使用类似的设计，并支持 Parquet 和 ORC 存储；Apache Hudi 始于 Uber 也类似，尽管它不支持并发写入（正在支持中），该系统侧重于简化流式数据入数据湖。 这些系统的经验表明它们可以提供与原始 Parquet/ORC 数据湖类似或更好的性能，同时还增加了非常有用的管理功能，例如事务处理，零拷贝和回滚。 元数据层对数据质量非常重要，例如可以对 Schema 进行校验，使其不破坏数据质量。 另外元数据层可以实现诸如访问控制和审核日志记录之类的治理功能，例如元数据层可以在授予客户端凭据以从云对象存储读取表中的原始数据之前，检查是否允许客户端访问表，并且记录所有访问行为。 未来方向和替代设计。由于数据湖的元数据层非常新，因此存在许多悬而未决的问题和替代设计。例如 Delta Lake 设计为将事务日志存储在它运行的同一对象存储中（例如 S3）以简化管理（消除了运行单独存储系统的需要）并提供高可用性和高读取带宽，但对象存储的高延迟限制了它可以支持的每秒事务处理速率，在某些情况下将元数据使用更快的存储系统的设计可能更可取。同样Delta Lake、Iceberg 和 Hudi 仅支持单表事务，但也可以扩展以支持跨表事务，优化事务日志的格式和管理对象的大小也是未解决的问题。 ","date":"2021-01-06","objectID":"/lakehouse/:4:2","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"Lakehouse 中的 SQL 性能 Lakehouse 方案的最大技术问题可能是如何提供最新的 SQL 性能，同时又放弃了传统 DBMS 设计中很大一部分的数据独立性，有很多解决方案，例如可以在对象存储上添加一个缓存层，以及是否可以更改数据对象存储格式而不使用现有的标准（例如 Parquet 和 ORC（不断改进这些格式的新设计不断涌现））。无论采用何种设计，核心挑战在于数据存储格式已成为系统公共 API 的一部分以允许快速直接访问，这与传统 DBMS 不同。 我们提出了几种技术可以在 Lakehouse 中优化 SQL 性能，并且与数据格式无关，因此可以将其与现有格式或未来数据格式一起使用，这些与格式无关的优化大致如下： 缓存：使用元数据层时，Lakehouse 系统可以安全地将云对象存储中的文件缓存在处理节点上更快的存储设备（例如 SSD 和 RAM）上，正在运行的事务可以确定读取缓存的文件是否还有效，此外缓存可以采用转码格式，其对于查询引擎运行效率更高，例如在 Databricks 的缓存会解压了部分它加载的 Parquet 数据。 辅助数据：即使 Lakehouse 为支持直接 I/O 访问需要开放表存储格式（如 Parquet），它也可以维护其他数据来帮助优化查询，如在 Parquet 文件中维护表中每个数据文件的列最小-最大统计信息，有助于跳过数据，以及基于 Bloom 过滤器的索引。可以实现各种各样的辅助数据结构，类似于为\"原始\"数据建立索引。 数据布局：数据布局在访问性能中起着重要作用。Lakehouse 系统也可以优化多个布局决策，最明显的是记录排序：哪些记录聚集在一起可以最容易被批量读取，Delta 中使用 Z-Order，Hudi 中使用基于哪些列进行 Clustering。 对于分析系统中的典型访问模式，这三个优化可以很好地协同工作。典型的工作负载中大多数查询倾向于集中在数据的\"热\"子集上，Lakehouse 可以使用与数据仓库相同的优化数据结构对其进行缓存，以提供相同的查询性能。对于云对象存储中的\"冷\"数据，性能的主要决定于每个查询读取的数据量，在该情况下数据布局优化（将共同访问的数据聚类）和辅助数据结构（如区域图，使引擎快速确定要读取的数据文件范围）的组合可以使Lakehouse系统与数仓一样最小化 I/O 开销，尽管使用标准的开放文件格式（相比于数仓内置文件格式）。 性能结果 TPC-DS比较 未来方向和替代设计。设计性能良好且可以直接访问的 Lakehouse 系统是未来工作的重点。一个尚待探索的方向是设计更好适应此类场景的数据湖存储格式，例如为 Lakehouse 系统实现数据布局优化或索引提供更大灵活性的存储格式，或者更适合现代硬件。 即使不改变数据格式，也有许多缓存策略、辅助数据结构和数据布局策略。哪一种对云对象存储中的海量数据集更有效是一个开放式问题。 最后，另一个值得研究的点是确定何时以及如何使用 serverless 计算系统来响应查询、优化存储、元数据层和查询引擎，以实现延迟最小化效果。 ","date":"2021-01-06","objectID":"/lakehouse/:4:3","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"高级分析高效访问 高级分析库通常不是使用 SQL 命令编写，其需要访问大量数据。作者认为需要研究以下问题：如何设计数据访问层，最大程度地提高顶部运行代码的灵活性，并且可以从 Lakehouse 的优化中受益？ 优化方案 作者验证了如上图所示的优化方案：将缓存、数据筛选、数据布局优化同时应用，实现了机器学习算法加速。 机器学习 API 迅速发展，但是一些数据访问 API（例如 TensorFlow 的 tf.data）没有尝试将查询语义推入底层存储系统，一些 API 还专注于 CPU 到 GPU 的传输和 GPU 计算，这在数据仓库中并未引起太多关注。 未来方向和替代设计。论文提出需要多关注机器学习系统的数据访问接口。近期一些机器学习框架将算法逻辑融合进 SQL join 操作，其他应用在算法中的查询优化应用在 SQL 中。最后，作者认为需要标准机器学习接口以使数据科学家能够充分利用 Lakehouse（甚至数据仓库）中强大的数据管理功能，如事务，数据版本控制和回滚等。 ","date":"2021-01-06","objectID":"/lakehouse/:4:4","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"研究问题和启示 Lakehouse 还提出了其他一些研究问题，功能日益丰富的数据湖的行业趋势也对数据系统研究的其他领域产生了影响。 还有其他方法可以实现 Lakehouse 目标吗？可以想像其他方法来实现 Lakehouse 的主要目标，例如构建用于数据仓库的大规模并行服务层，可以支持对高级分析工作负载的并行读取，但是与工作负载直接访问对象存储库相比成本将更高，难以管理，并且性能可能会降低。这种服务层并未得到广泛应用，例如 Hive LLAP。 除了在性能、可用性、成本和锁定方面的挑战外，还有一些重要的管理原因，如企业可能更喜欢将数据保留为开放格式。随着对数据管理的法规要求不断提高，组织可能需要在短时间内搜索旧数据集，删除各种数据或更改其数据处理基础结构，并且采用开放格式进行标准化意味着它们将始终可以直接访问数据，软件行业的长期趋势一直是开放数据格式，企业数据应该继续保持这种趋势。 什么是正确的存储格式和访问 API？Lakehouse 的访问接口包括原始存储格式以及直接读取此格式的客户端库（例如使用 TensorFlow 读取时）以及高级 SQL 接口。有很多不同的方法可以在这些层上放置丰富的功能，例如通过要求读者执行更复杂的“可编程”解码逻辑，可以为系统提供更大的灵活性的存储方案。有待观察哪种存储格式、元数据层设计和访问 API 的组合效果最佳。 Lakehouse 如何影响其他数据管理研究和趋势？数据湖的流行以及对丰富管理接口的使用不断增加，无论它们是元数据层还是完整的 Lakehouse 设计，都对数据管理研究的其他领域产生了影响。 Polystore 旨在解决跨不同存储引擎查询数据这一难题，该问题在企业中持续存在，但是在云数据湖中以开放格式提供的数据比例越来越高，也可以通过直接针对云对象存储运行许多 polystore 查询，即使基础数据文件是逻辑上分开的 Lakehouse 的一部分。 还可以在 Lakehouse 上设计数据集成和清理工具，并可以快速并行访问所有数据，这可以用于大型联接和聚类等新算法。 可以将 HTAP 系统构建为 Lakehouse 前面的\"附加\"层，通过使用其事务管理 API 将数据直接归档到 Lakehouse 系统中，Lakehouse 将能够查询数据的一致快照。 ML 的数据管理也会变得更加简单和强大，如今组织正在构建各种可重新实现标准 DBMS 功能的，特定于 ML 的数据版本控制和特征存储系统，使用带有内置 DBMS 管理功能的数据湖来实现特征存储功能可能会更简单。 Serverless 引擎之类的云原生 DBMS 设计将需要与更丰富的元数据层集成，而不是直接扫描数据湖中的原始文件，可以能够提高查询性能。 最后 Lakehouse 的设计易于分布式协作，因为可以从对象存储库直接访问所有数据集，这使得共享数据变得很简单。 ","date":"2021-01-06","objectID":"/lakehouse/:5:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"},{"categories":["论文学习"],"content":"结论 在开放的数据湖文件格式上实现数据仓库功能的统一数据平台体系架构可以为当今的数据仓库系统提供具有竞争力的性能，并有助于应对数据仓库用户面临的许多挑战，尽管限制数据仓库的存储层以标准格式直接访问看起来似乎是一个重大限制，但诸如热数据缓存和冷数据数据布局优化之类的优化可以使 Lakehouse 获得很不错的性能，另外鉴于数据湖中已有大量数据，并且有机会大大简化企业数据架构，行业很可能会向 Lakehouse 架构逐步过渡。 ","date":"2021-01-06","objectID":"/lakehouse/:6:0","tags":["论文","数据湖","数据仓库","数据分析"],"title":"Lakehouse：统一数据仓库和高级分析的开放数据平台","uri":"/lakehouse/"}]